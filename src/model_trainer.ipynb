{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto para la prediccion de nota usando la opinion del estudiante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Requirement already up-to-date: gensim in /usr/local/lib/python3.7/site-packages (3.8.3)',\n",
       " 'Requirement already satisfied, skipping upgrade: numpy>=1.11.3 in /usr/local/lib/python3.7/site-packages (from gensim) (1.18.2)',\n",
       " 'Requirement already satisfied, skipping upgrade: six>=1.5.0 in /usr/local/lib/python3.7/site-packages (from gensim) (1.14.0)',\n",
       " 'Requirement already satisfied, skipping upgrade: smart-open>=1.8.1 in /usr/local/lib/python3.7/site-packages (from gensim) (2.0.0)',\n",
       " 'Requirement already satisfied, skipping upgrade: scipy>=0.18.1 in /usr/local/lib/python3.7/site-packages (from gensim) (1.5.0)',\n",
       " 'Requirement already satisfied, skipping upgrade: boto in /usr/local/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.49.0)',\n",
       " 'Requirement already satisfied, skipping upgrade: boto3 in /usr/local/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (1.14.12)',\n",
       " 'Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.7/site-packages (from smart-open>=1.8.1->gensim) (2.23.0)',\n",
       " 'Requirement already satisfied, skipping upgrade: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.10.0)',\n",
       " 'Requirement already satisfied, skipping upgrade: s3transfer<0.4.0,>=0.3.0 in /usr/local/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (0.3.3)',\n",
       " 'Requirement already satisfied, skipping upgrade: botocore<1.18.0,>=1.17.12 in /usr/local/lib/python3.7/site-packages (from boto3->smart-open>=1.8.1->gensim) (1.17.12)',\n",
       " 'Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2.9)',\n",
       " 'Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (2019.11.28)',\n",
       " 'Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (3.0.4)',\n",
       " 'Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->smart-open>=1.8.1->gensim) (1.25.8)',\n",
       " 'Requirement already satisfied, skipping upgrade: python-dateutil<3.0.0,>=2.1 in /usr/local/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.12->boto3->smart-open>=1.8.1->gensim) (2.8.1)',\n",
       " 'Requirement already satisfied, skipping upgrade: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/site-packages (from botocore<1.18.0,>=1.17.12->boto3->smart-open>=1.8.1->gensim) (0.15.2)']"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "!!pip3 install beautifulsoup4\n",
    "!!pip3 install -U scikit-learn\n",
    "!!pip3 install -U nltk\n",
    "!!pip3 install -U gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "aHc-cd-LYgeo"
   },
   "outputs": [],
   "source": [
    "import reviews_scraper # Script para tomar las reseñas de internet\n",
    "import nltk\n",
    "from sklearn import preprocessing\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import numpy as np\n",
    "import re\n",
    "import pandas as pd\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\" iurls_unal = reviews_scraper.get_urls_unal()\n",
    "urls_andes = reviews_scraper.get_urls_uniandes()\n",
    "all_urls = urls_andes + urls_unal \"\"\"\n",
    "\n",
    "results ={}\n",
    "differences={}\n",
    "train_data = reviews_scraper.get_train_data(\"\")\n",
    "df = pd.DataFrame(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 348
    },
    "colab_type": "code",
    "id": "8FpWJgbuZLjL",
    "outputId": "183ab215-4ad9-4661-d9ad-ac045c556093",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    7677\n",
      "1    7677\n",
      "2    7677\n",
      "dtype: int64\n",
      "0    24399\n",
      "1    24399\n",
      "2    24399\n",
      "dtype: int64\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Es lo peor en serio no explica nada, no es cla...</td>\n",
       "      <td>2</td>\n",
       "      <td>https://losestudiantes.co/universidad-de-los-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Todo un amor de profesor, no sé como sea para ...</td>\n",
       "      <td>5</td>\n",
       "      <td>https://losestudiantes.co/universidad-de-los-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>El CBU es un poco aburrido si no te interesa e...</td>\n",
       "      <td>3.5</td>\n",
       "      <td>https://losestudiantes.co/universidad-de-los-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Es la clase más aburrida que he visto en la un...</td>\n",
       "      <td>1.5</td>\n",
       "      <td>https://losestudiantes.co/universidad-de-los-a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Hernando es muy buena persona, en realidad es ...</td>\n",
       "      <td>4</td>\n",
       "      <td>https://losestudiantes.co/universidad-de-los-a...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0    1  \\\n",
       "0  Es lo peor en serio no explica nada, no es cla...    2   \n",
       "1  Todo un amor de profesor, no sé como sea para ...    5   \n",
       "2  El CBU es un poco aburrido si no te interesa e...  3.5   \n",
       "3  Es la clase más aburrida que he visto en la un...  1.5   \n",
       "4  Hernando es muy buena persona, en realidad es ...    4   \n",
       "\n",
       "                                                   2  \n",
       "0  https://losestudiantes.co/universidad-de-los-a...  \n",
       "1  https://losestudiantes.co/universidad-de-los-a...  \n",
       "2  https://losestudiantes.co/universidad-de-los-a...  \n",
       "3  https://losestudiantes.co/universidad-de-los-a...  \n",
       "4  https://losestudiantes.co/universidad-de-los-a...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"Checkear cuantos 5 hay\"\"\"\n",
    "print(df[df[1] == \"5\"].count())\n",
    "print(df.count())\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/freddyalejandro/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download(\"stopwords\")\n",
    "def preprocessing(doc):\n",
    "    wpt=nltk.WordPunctTokenizer()\n",
    "    stop_words=nltk.corpus.stopwords.words('spanish')\n",
    "    # Se eliminan caracteres especiales\n",
    "    replacements = ((\"á\", \"a\"), (\"é\", \"e\"), (\"í\", \"i\"), (\"ó\", \"o\"),\n",
    "                    (\"ú\", \"u\"))\n",
    "    for a, b in replacements:\n",
    "        doc = doc.replace(a, b)\n",
    "    doc=re.sub(r'[^a-zA-Z\\sñ]', '', doc, re.I|re.A)\n",
    "    # Se convierten los téxtos a minúsculas\n",
    "    doc=doc.lower()\n",
    "    doc.strip(\"\\n\")\n",
    "    # Se separan signos de puntuación\n",
    "    tokens=wpt.tokenize(doc)\n",
    "    # Se eliminan las stopwords\n",
    "    tokens=[token for token in tokens if token not in stop_words and len(token)>2]\n",
    "    # Retornamos una versión filtrada del texto\n",
    "    return ' '.join(tokens)\n",
    "def my_round(x, base=5):\n",
    "    x*=10\n",
    "    return str(int(base*round(x/base))/10)\n",
    "def my_round_ceil(x, base=5):\n",
    "    x*=10\n",
    "    return str(int(base*math.ceil(x/base))/10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df)):\n",
    "    df.iloc[i][0]=preprocessing(df.iloc[i][0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion\n",
    "Primero se probara un enfoque de clasificacion donde cada posible nota es un grupo y por una nueva opinion se intentara predecir la nota pensada.\n",
    "\n",
    "### Clasificacion Discreta\n",
    "En esta  clasificacion tendremos un enfoque discreto, es decir cada valor sera una etiqueta(string) y no un valor numerio, por tanto la prediccion estara ligada a esto datos discretos.\n",
    "\n",
    "#### Se usara Word2Vect para la representacion del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import word2vec\n",
    "\n",
    "feature_size = 100 \n",
    "window_context = 5 \n",
    "min_word_count = 10\n",
    "sample = 1e-3\n",
    "\n",
    "# Escriba su código aquí\n",
    "\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "tokenized_corpus = [wpt.tokenize(document) for document in df[0]]\n",
    "\n",
    "\n",
    "w2v_model = word2vec.Word2Vec(tokenized_corpus, size=feature_size,\n",
    "                              window=window_context, min_count=min_word_count,\n",
    "                              sample=sample, iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def w2v_repr1(corpus, ):\n",
    "    repr1 = [] \n",
    "    for item in corpus: \n",
    "      vectors = [] \n",
    "      vectors.append(np.zeros(feature_size))\n",
    "      for word in item.split(\" \"): \n",
    "        try:\n",
    "          vectors.append(w2v_model.wv[word])\n",
    "        except:\n",
    "          pass\n",
    "      average = np.average(vectors, axis=0)\n",
    "      repr1.append(average)\n",
    "    return repr1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Entrenamiento de  un modelo bayesiano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import *\n",
    "nb_model = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seleccion de datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.33737705 0.34377049 0.33754098 0.33677652]\n"
     ]
    }
   ],
   "source": [
    "X = w2v_repr1(df[0].to_numpy())\n",
    "y=[my_round(float(x)) for x in df[1].to_numpy()]\n",
    "kfold = KFold(4, True, 0,shuffle=True, random_state=0 )\n",
    "folds =list(kfold.split(X))\n",
    "score=cross_val_score(nb_model, X, y, cv=folds)\n",
    "print(score)\n",
    "max_score_index =np.argmax(score)\n",
    "train,test=folds[max_score_index]\n",
    "x_train,x_test,y_train,y_test = np.array(X)[train],np.array(X)[test],np.array(y)[train],np.array(y)[test]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usamos Cross validation con un fold del 25% \n",
    "## Analizando la precision de la clasificacion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entrenamiento\n",
    "nb_model.fit(x_train, y_train)\n",
    "# Prediction \n",
    "predictions = nb_model.predict(x_test)\n",
    "\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_precision(y_t,predict):\n",
    "    r2_s = r2_score([float(x) for x in y_t],[float(p) for p in predict])\n",
    "    print(\"Error cuadratico medio asumiendo que los resultados son valores continuos: \",r2_s)\n",
    "    print(classification_report(y_t,predict))\n",
    "    print(\"Accuracy + Gaussian: \",accuracy_score(y_t,predict))\n",
    "    return r2_s\n",
    "\n",
    "def print_tests(y_t,predict,preproc,rep,m):\n",
    "    predict_number = [float(p) for p in predict]\n",
    "    y_t_number = [float(t) for t in y_t]\n",
    "    error={}\n",
    "    l=len(y_t_number)\n",
    "    for i in range(l):\n",
    "        diff = abs(y_t_number[i]-predict_number[i])\n",
    "        if diff in error:\n",
    "            error[diff]+=1\n",
    "        else:\n",
    "            error[diff]=1\n",
    "    for k in error.keys():\n",
    "        error[k]=round(error[k]/l,2)\n",
    "    print(sorted(error.items()))\n",
    "    test1=\"es el mejor profesor del mundo enseña muy bien hace las clases dinamicas\"\n",
    "    test2=\"sus parciales son muy dificiles pero enseña bien\"\n",
    "    test3=\"No se aprende nada en la materia pero al menos se pasa\"\n",
    "    test4=\"La clase son solo tareas que pueden ser un poco largas, pero todo el tiempo de la clase se va en historias que poco o nada tienen que ver con los temas de la materia. Explica muy poca teoría.\"\n",
    "    tests =[test1,test2,test3,test4]\n",
    "    for i in range(len(tests)):\n",
    "        tests[i]=preproc(tests[i])\n",
    "    val = rep(tests)\n",
    "    test_predictions=(m.predict(val))\n",
    "    for i in range(len(tests)):\n",
    "        print(\"Entrada: \",tests[i],\"\\nPrediccion: \",test_predictions[i])\n",
    "    return sorted(error.items())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio asumiendo que los resultados son valores continuos:  0.12244423135374227\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.14      0.27      0.19       192\n",
      "         1.5       0.40      0.33      0.36       336\n",
      "         2.0       0.15      0.19      0.17       381\n",
      "         2.5       0.15      0.16      0.15       214\n",
      "         3.0       0.18      0.16      0.17       488\n",
      "         3.5       0.18      0.27      0.22       462\n",
      "         4.0       0.27      0.21      0.24       971\n",
      "         4.5       0.25      0.32      0.28       942\n",
      "         5.0       0.67      0.53      0.59      2114\n",
      "\n",
      "    accuracy                           0.34      6100\n",
      "   macro avg       0.27      0.27      0.26      6100\n",
      "weighted avg       0.38      0.34      0.36      6100\n",
      "\n",
      "Accuracy + Gaussian:  0.3437704918032787\n"
     ]
    }
   ],
   "source": [
    "results['w2v_d']=print_precision(y_test,predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados son bastante malos, esto puede ser debido a que una prediccion erronea se toma cuando los valores son difentes, aun si estos estan cerca, por ejemplo la prediccion da como resultado 3, y el valor real era 3.5, debido a esto se hara una clasificacion continua usando regresion lineal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.34), (0.5, 0.32), (1.0, 0.15), (1.5, 0.07), (2.0, 0.04), (2.5, 0.03), (3.0, 0.02), (3.5, 0.01), (4.0, 0.01)]\n",
      "Entrada:  mejor profesor mundo enseña bien hace clases dinamicas \n",
      "Prediccion:  5.0\n",
      "Entrada:  parciales dificiles enseña bien \n",
      "Prediccion:  4.0\n",
      "Entrada:  aprende materia menos pasa \n",
      "Prediccion:  1.5\n",
      "Entrada:  clase solo tareas pueden ser largas tiempo clase historias ver temas materia explica poca teoria \n",
      "Prediccion:  3.0\n"
     ]
    }
   ],
   "source": [
    "differences['w2v_d']=print_tests(y_test, predictions,preprocessing,w2v_repr1,nb_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar aproximandamente el 65% de resultados de las predicciones estan tienen un 0.5 de diferencia con el valor real, otro 15% esta con una diferencia de 1 al valor real, y el resto esta con un valor mayor. Esto hace ver que medir la precision de este modelo con las metricas para valores discretos, no solo poco diciente, si no que ademas es engañoso. Por tanto se hara una clasificacion con un enfoque continuo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion Continua\n",
    "En este caso haremos una clasificacion con valores continuos en lugar de tomar cada valor como una posible etiqueta. Se usara la misma representacion, WordVect.\n",
    "Para esta clasificacion se hara una regresion lineal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "from sklearn.linear_model import LinearRegression\n",
    "lr = LinearRegression(fit_intercept=False, normalize=False, copy_X=False, n_jobs=-1)\n",
    "## debemos tener nuestra etiquetas como numeros y no como strings\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.49042148 0.48299324 0.45324722 0.45387023]\n"
     ]
    }
   ],
   "source": [
    "X = w2v_repr1(df[0].to_numpy())\n",
    "y=[(float(x)) for x in df[1].to_numpy()]\n",
    "kfold = KFold(4, True, 0,shuffle=True, random_state=0 )\n",
    "folds =list(kfold.split(X))\n",
    "score=cross_val_score(lr, X, y, cv=folds, scoring='r2')\n",
    "print(score)\n",
    "max_score_index =np.argmax(score)\n",
    "train,test=folds[max_score_index]\n",
    "x_train,x_test,y_train,y_test = np.array(X)[train],np.array(X)[test],np.array(y)[train],np.array(y)[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=False, fit_intercept=False, n_jobs=-1)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analisis de resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4904214794492292\n"
     ]
    }
   ],
   "source": [
    "performance = lr.score(x_test, y_test)\n",
    "results['w2v_c']=performance\n",
    "print(performance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos una mejora bastante significativa en el r2 en relacion con el resultado anterior. El r2 esta cerca a 0.5 lo cual es bueno segun algunas interpretaciones de este puntaje.La interpretacion de este score depende del tipo de problema, si fuera algo netamente matematico este score seria malo, pero al tratarse de analisis de lenguaje natural es algo al menos aceptable que aun se puede mejorar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entrada:  mejor profesor mundo enseña bien hace clases dinamicas \n",
      "Prediccion:  4.78\n",
      "Entrada:  parciales dificiles enseña bien \n",
      "Prediccion:  2.83\n",
      "Entrada:  aprende materia menos pasa \n",
      "Prediccion:  1.28\n",
      "Entrada:  clase solo tareas pueden ser largas tiempo clase historias ver temas materia explica poca teoria \n",
      "Prediccion:  3.58\n"
     ]
    }
   ],
   "source": [
    "test1=\"es el mejor profesor del mundo enseña muy bien hace las clases dinamicas\"\n",
    "test2=\"sus parciales son muy dificiles pero enseña bien\"\n",
    "test3=\"No se aprende nada en la materia pero al menos se pasa\"\n",
    "test4=\"La clase son solo tareas que pueden ser un poco largas, pero todo el tiempo de la clase se va en historias que poco o nada tienen que ver con los temas de la materia. Explica muy poca teoría.\"\n",
    "tests =[test1,test2,test3,test4]\n",
    "for i in range(len(tests)):\n",
    "    tests[i]=preprocessing(tests[i])\n",
    "val = w2v_repr1(tests)\n",
    "test_predictions=(lr.predict(val))\n",
    "for i in range(len(tests)):\n",
    "    print(\"Entrada: \",tests[i],\"\\nPrediccion: \",round(test_predictions[i],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0.0', 0.26), ('0.5', 0.4), ('1.0', 0.21), ('1.5', 0.08), ('2.0', 0.03), ('2.5', 0.01), ('3.0', 0.0), ('3.5', 0.0), ('4.5', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "predict = lr.predict(x_test)\n",
    "error={}\n",
    "l=len(y_test)\n",
    "for i in range(l):\n",
    "    diff = my_round(abs(y_test[i]-predict[i]))\n",
    "    if diff in error:\n",
    "        error[diff]+=1\n",
    "    else:\n",
    "        error[diff]=1\n",
    "for k in error.keys():\n",
    "    error[k]=round(error[k]/l,2)\n",
    "print(sorted(error.items()))\n",
    "differences['w2v_c']=sorted(error.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion con analisis de sentimientos\n",
    "\n",
    "Ahora se probara hacer una clasificacion pero tomando como datos de entrada no el texto, si no el resultado de analisis de sentimiento del texto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Requirement already satisfied: googletrans in /usr/local/lib/python3.7/site-packages (3.0.0)',\n",
       " 'Requirement already satisfied: httpx==0.13.3 in /usr/local/lib/python3.7/site-packages (from googletrans) (0.13.3)',\n",
       " 'Requirement already satisfied: certifi in /usr/local/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (2019.11.28)',\n",
       " 'Requirement already satisfied: hstspreload in /usr/local/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (2020.6.23)',\n",
       " 'Requirement already satisfied: idna==2.* in /usr/local/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (2.9)',\n",
       " 'Requirement already satisfied: httpcore==0.9.* in /usr/local/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (0.9.1)',\n",
       " 'Requirement already satisfied: chardet==3.* in /usr/local/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (3.0.4)',\n",
       " 'Requirement already satisfied: rfc3986<2,>=1.3 in /usr/local/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (1.4.0)',\n",
       " 'Requirement already satisfied: sniffio in /usr/local/lib/python3.7/site-packages (from httpx==0.13.3->googletrans) (1.1.0)',\n",
       " 'Requirement already satisfied: h2==3.* in /usr/local/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (3.2.0)',\n",
       " 'Requirement already satisfied: h11<0.10,>=0.8 in /usr/local/lib/python3.7/site-packages (from httpcore==0.9.*->httpx==0.13.3->googletrans) (0.9.0)',\n",
       " 'Requirement already satisfied: hyperframe<6,>=5.2.0 in /usr/local/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (5.2.0)',\n",
       " 'Requirement already satisfied: hpack<4,>=3.0 in /usr/local/lib/python3.7/site-packages (from h2==3.*->httpcore==0.9.*->httpx==0.13.3->googletrans) (3.0.0)']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Instalación de VADER\n",
    "!!pip3 install vaderSentiment\n",
    "#!!pip3 install pydeepl\n",
    "!!pip3 install googletrans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = reviews_scraper.get_train_data(\"\")\n",
    "df = pd.DataFrame(train_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que VADER solo funciona para ingles es necesario hacer la traduccion del texto, eso puede hacer que se pierda un poco la precision. Tambien es necesaria cambiar el prepocesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/reviews_translated/reviews_translated_0.json\n",
      "./data/reviews_translated/reviews_translated_1.json\n",
      "./data/reviews_translated/reviews_translated_2.json\n",
      "./data/reviews_translated/reviews_translated_3.json\n",
      "./data/reviews_translated/reviews_translated_4.json\n",
      "./data/reviews_translated/reviews_translated_5.json\n",
      "./data/reviews_translated/reviews_translated_6.json\n",
      "./data/reviews_translated/reviews_translated_7.json\n",
      "./data/reviews_translated/reviews_translated_8.json\n",
      "./data/reviews_translated/reviews_translated_9.json\n",
      "./data/reviews_translated/reviews_translated_10.json\n",
      "./data/reviews_translated/reviews_translated_11.json\n",
      "./data/reviews_translated/reviews_translated_12.json\n",
      "./data/reviews_translated/reviews_translated_13.json\n",
      "./data/reviews_translated/reviews_translated_14.json\n",
      "./data/reviews_translated/reviews_translated_15.json\n",
      "./data/reviews_translated/reviews_translated_16.json\n",
      "./data/reviews_translated/reviews_translated_17.json\n",
      "./data/reviews_translated/reviews_translated_18.json\n",
      "./data/reviews_translated/reviews_translated_19.json\n",
      "./data/reviews_translated/reviews_translated_20.json\n",
      "./data/reviews_translated/reviews_translated_21.json\n",
      "./data/reviews_translated/reviews_translated_22.json\n",
      "./data/reviews_translated/reviews_translated_23.json\n",
      "./data/reviews_translated/reviews_translated_24.json\n"
     ]
    }
   ],
   "source": [
    "from translate_utils import get_translated_reviews,translate_sentence\n",
    "size = 25\n",
    "bash = math.ceil(len(df[0].index)/size)\n",
    "path_file = \"./data/reviews_translated/reviews_translated_{}.json\"\n",
    "reviews_df=[]\n",
    "\n",
    "for i in range(size):\n",
    "    print(path_file.format(i))\n",
    "    \n",
    "    reviews_df.append(get_translated_reviews(pd.DataFrame(df[i*bash:(i+1)*bash]),8,path_file.format(i)))\n",
    "reviews_translated = pd.concat(reviews_df)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24355\n"
     ]
    }
   ],
   "source": [
    "print(len(reviews_translated[0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing_en(doc):\n",
    "    wpt=nltk.WordPunctTokenizer()\n",
    "    stop_words=nltk.corpus.stopwords.words('english')\n",
    "    # Se eliminan caracteres especiales\n",
    "    doc=re.sub(r'[^a-zA-Z\\s]', '', doc, re.I|re.A)\n",
    "    # Se convierten los téxtos a minúsculas\n",
    "    doc=doc.lower()\n",
    "    doc.strip(\"\\n\")\n",
    "    # Se separan signos de puntuación\n",
    "    tokens=wpt.tokenize(doc)\n",
    "    # Se eliminan las stopwords\n",
    "    tokens=[token for token in tokens if token not in stop_words and len(token)>2]\n",
    "    # Retornamos una versión filtrada del texto\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(reviews_translated)):\n",
    "    reviews_translated.iloc[i][0]=preprocessing_en(reviews_translated.iloc[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "# Creamos un analizador de sentimientos\n",
    "analyzer=SentimentIntensityAnalyzer()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_to_sentiment_values(doc):\n",
    "    sentiment_values = []\n",
    "    for d in doc:\n",
    "        sentiment_values.append(list(analyzer.polarity_scores(d).values()))\n",
    "    return sentiment_values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [y[0] for y in  reviews_translated[1].to_numpy()]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion Discreta con analisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_s = GaussianNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.38134341 0.37280342 0.38544917 0.3901117 ]\n"
     ]
    }
   ],
   "source": [
    "X = doc_to_sentiment_values(reviews_translated[0].to_numpy())\n",
    "y=[my_round(float(x)) for x in notes]\n",
    "kfold = KFold(4, True, 0,shuffle=True, random_state=0 )\n",
    "folds =list(kfold.split(X))\n",
    "score=cross_val_score(nb_model_s, X, y, cv=folds)\n",
    "print(score)\n",
    "max_score_index =np.argmax(score)\n",
    "train,test=folds[max_score_index]\n",
    "x_train,x_test,y_train,y_test = np.array(X)[train],np.array(X)[test],np.array(y)[train],np.array(y)[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error cuadratico medio asumiendo que los resultados son valores continuos:  0.02677097632125902\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         1.0       0.00      0.00      0.00       158\n",
      "         1.5       0.25      0.50      0.33       335\n",
      "         2.0       0.10      0.06      0.07       362\n",
      "         2.5       0.00      0.00      0.00       179\n",
      "         3.0       0.15      0.10      0.12       465\n",
      "         3.5       0.00      0.00      0.00       455\n",
      "         4.0       0.25      0.24      0.24      1011\n",
      "         4.5       0.15      0.00      0.01       981\n",
      "         5.0       0.49      0.88      0.63      2142\n",
      "\n",
      "    accuracy                           0.39      6088\n",
      "   macro avg       0.15      0.20      0.16      6088\n",
      "weighted avg       0.27      0.39      0.29      6088\n",
      "\n",
      "Accuracy + Gaussian:  0.39011169513797633\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Entrenamiento\n",
    "nb_model_s.fit(x_train, y_train)\n",
    "# Prediction \n",
    "predictions_s = nb_model_s.predict(x_test)\n",
    "\n",
    "results['sent_d']=print_precision(y_test,predictions_s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como se puede observar los resultados son mas malos usando solo un analisis de sentimientos que cuando usamos word2vetc, esto en parte se puede deber a la traduccion que obviamente no es pefecta pues se uso usando google translator "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0.0, 0.39), (0.5, 0.22), (1.0, 0.18), (1.5, 0.07), (2.0, 0.06), (2.5, 0.03), (3.0, 0.03), (3.5, 0.02), (4.0, 0.0)]\n",
      "Entrada:  mejor profesor del mundo ensea muy bien hace las clases dinamicas \n",
      "Prediccion:  5.0\n",
      "Entrada:  sus parciales son muy dificiles pero ensea bien \n",
      "Prediccion:  4.0\n",
      "Entrada:  aprende nada materia pero menos pasa \n",
      "Prediccion:  2.0\n",
      "Entrada:  clase son solo tareas que pueden ser poco largas pero todo tiempo clase historias que poco nada tienen que ver con los temas materia explica muy poca teora \n",
      "Prediccion:  2.0\n"
     ]
    }
   ],
   "source": [
    "def  translate_senr_en(doc):\n",
    "    new_doc=[translate_sentence(d) for d in doc]\n",
    "    return doc_to_sentiment_values(new_doc)\n",
    "\n",
    "differences['sent_d']=print_tests(y_test,predictions_s,preprocessing_en,translate_senr_en,nb_model_s)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion continua con analisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "lr_s = LinearRegression(fit_intercept=False, normalize=False, copy_X=False, n_jobs=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.40664235 0.39766494 0.40216853 0.38454014]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/sklearn/utils/validation.py:71: FutureWarning: Pass shuffle=True, random_state=0 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X = doc_to_sentiment_values(reviews_translated[0].to_numpy())\n",
    "y=[float(x) for x in notes]\n",
    "kfold = KFold(4, True, 0,shuffle=True, random_state=0 )\n",
    "folds =list(kfold.split(X))\n",
    "score=cross_val_score(lr_s, X, y, cv=folds,scoring='r2')\n",
    "print(score)\n",
    "max_score_index =np.argmax(score)\n",
    "train,test=folds[max_score_index]\n",
    "x_train,x_test,y_train,y_test = np.array(X)[train],np.array(X)[test],np.array(y)[train],np.array(y)[test]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4066423525964883\n",
      "Entrada:  best teacher world teaches well dynamic classes \n",
      "Prediccion:  4.87\n",
      "Entrada:  partials difficult teaches well \n",
      "Prediccion:  2.95\n",
      "Entrada:  nothing learned subject least passed \n",
      "Prediccion:  3.2\n",
      "Entrada:  class homework bit long class time goes stories little nothing subject matter explains little theory \n",
      "Prediccion:  3.35\n"
     ]
    }
   ],
   "source": [
    "lr_s.fit(x_train, y_train)\n",
    "performance = lr_s.score(x_test, y_test)\n",
    "results['sent_c'] = performance\n",
    "print(performance)\n",
    "test1=\"es el mejor profesor del mundo enseña muy bien hace las clases dinamicas\"\n",
    "test2=\"sus parciales son muy dificiles pero enseña bien\"\n",
    "test3=\"No se aprende nada en la materia pero al menos se pasa\"\n",
    "test4=\"La clase son solo tareas que pueden ser un poco largas, pero todo el tiempo de la clase se va en historias que poco o nada tienen que ver con los temas de la materia. Explica muy poca teoría.\"\n",
    "tests =[test1,test2,test3,test4]\n",
    "for i in range(len(tests)):\n",
    "    tests[i]=preprocessing_en(translate_sentence(tests[i]))\n",
    "val = doc_to_sentiment_values(tests)\n",
    "test_predictions=(lr_s.predict(val))\n",
    "for i in range(len(tests)):\n",
    "    print(\"Entrada: \",tests[i],\"\\nPrediccion: \",round(test_predictions[i],2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('0.0', 0.22), ('0.5', 0.43), ('1.0', 0.2), ('1.5', 0.08), ('2.0', 0.04), ('2.5', 0.02), ('3.0', 0.01), ('3.5', 0.0), ('4.5', 0.0)]\n"
     ]
    }
   ],
   "source": [
    "predict = lr_s.predict(x_test)\n",
    "error={}\n",
    "l=len(y_test)\n",
    "for i in range(l):\n",
    "    diff = my_round(abs(y_test[i]-predict[i]))\n",
    "    if diff in error:\n",
    "        error[diff]+=1\n",
    "    else:\n",
    "        error[diff]=1\n",
    "for k in error.keys():\n",
    "    error[k]=round(error[k]/l,2)\n",
    "print(sorted(error.items()))\n",
    "differences['sent_c']=sorted(error.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usando el analisis de sentimientos como entrada para la clasificacion vemos que el r2 da cercano a 0.4 lo cual es inferior al resultado usando word2vect, esto puede darnos nuevas relaciones entre el texto de entrada y la salida o simplemente estar remarcando las ya existentes. Para verificar lo dicho se hara una ultima clasificacion mezclando los dos metodos, word2vect y analisis de sentimientos.\n",
    "\n",
    "### clasificacion word2vect + analisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = reviews_scraper.get_train_data(\"\")\n",
    "df = pd.DataFrame(train_data)\n",
    "for i in range(len(df)):\n",
    "    df.iloc[i][0]=preprocessing(df.iloc[i][0])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "notes = [y[0] for y in  reviews_translated[1].to_numpy()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_x_total = w2v_repr1(df[0].to_numpy())\n",
    "sent_x_total =  doc_to_sentiment_values(reviews_translated[0].to_numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(w2v_x_total))\n",
    "print(len(sent_x_total))\n",
    "print(len(reviews_translated[0].index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_sent_x_total=[0]*len(sent_x_total)\n",
    "\n",
    "for i in range(len(sent_x_total)):\n",
    "    w2v_sent_x_total[i]=(sent_x_total[i]) +list(w2v_x_total[reviews_translated.iloc[i][1][1]])\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Clasificacion discreta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_model_ws = GaussianNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = w2v_sent_x_total\n",
    "y=[my_round(float(x)) for x in notes]\n",
    "kfold = KFold(4, True, 0,shuffle=True, random_state=0 )\n",
    "folds =list(kfold.split(X))\n",
    "score=cross_val_score(nb_model_ws, X, y, cv=folds)\n",
    "print(score)\n",
    "max_score_index =np.argmax(score)\n",
    "train,test=folds[max_score_index]\n",
    "x_train,x_test,y_train,y_test = np.array(X)[train],np.array(X)[test],np.array(y)[train],np.array(y)[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Entrenamiento\n",
    "nb_model_ws.fit(x_train, y_train)\n",
    "# Prediction \n",
    "predictions_ws = nb_model_ws.predict(x_test)\n",
    "\n",
    "\n",
    "print_precision(y_test,predictions_ws)\n",
    "predict_number = [float(p) for p in predictions_ws]\n",
    "y_t_number = [float(t) for t in y_test]\n",
    "results['w2v_sent_d']=r2_score(y_t_number,predict_number)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_number_ws = [float(p) for p in predictions_ws]\n",
    "y_t_number_ws = [float(t) for t in y_test]\n",
    "error ={}\n",
    "for i in range(len(predict_number_ws)):\n",
    "    diff=abs(predict_number_ws[i] - y_t_number_ws[i])\n",
    "    if diff in error:\n",
    "        error[diff]+=1\n",
    "    else:\n",
    "        error[diff]=1\n",
    "for k in error.keys():\n",
    "    error[k] = round(error[k]/len(predict_number_ws), 2)\n",
    "print(sorted(error.items()))\n",
    "differences['w2v_sent_d']= sorted(error.items())\n",
    "test1=\"es el mejor profesor del mundo enseña muy bien hace las clases dinamicas\"\n",
    "test2=\"sus parciales son muy dificiles pero enseña bien\"\n",
    "test3=\"No se aprende nada en la materia pero al menos se pasa\"\n",
    "test4=\"La clase son solo tareas que pueden ser un poco largas, pero todo el tiempo de la clase se va en historias que poco o nada tienen que ver con los temas de la materia. Explica muy poca teoría.\"\n",
    "tests =[test1,test2,test3,test4]\n",
    "for i in range(len(tests)):\n",
    "    tests[i]=preprocessing_en(translate_sentence(tests[i]))\n",
    "sent=doc_to_sentiment_values(tests)\n",
    "test1=\"es el mejor profesor del mundo enseña muy bien hace las clases dinamicas\"\n",
    "test2=\"sus parciales son muy dificiles pero enseña bien\"\n",
    "test3=\"No se aprende nada en la materia pero al menos se pasa\"\n",
    "test4=\"La clase son solo tareas que pueden ser un poco largas, pero todo el tiempo de la clase se va en historias que poco o nada tienen que ver con los temas de la materia. Explica muy poca teoría.\"\n",
    "tests =[test1,test2,test3,test4]\n",
    "for i in range(len(tests)):\n",
    "    tests[i]=preprocessing(tests[i])\n",
    "w2v=w2v_repr1(tests)\n",
    "val = []\n",
    "for i in range(len(sent)):\n",
    "    val.append(sent[i]+list(w2v[i]))\n",
    "print(len(val))\n",
    "test_predictions =nb_model_ws.predict(val)\n",
    "for i in range(len(tests)):\n",
    "    print(\"Entrada: \",tests[i],\"\\nPrediccion: \",test_predictions[i])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clasificacion contiunua word2vect+analisis de sentimientos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ws = LinearRegression(fit_intercept=False, normalize=False, copy_X=False, n_jobs=-1)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = w2v_sent_x_total\n",
    "y=[(float(x)) for x in notes]\n",
    "kfold = KFold(4, True, 0,shuffle=True, random_state=0 )\n",
    "folds =list(kfold.split(X))\n",
    "score=cross_val_score(lr_ws, X, y, cv=folds,scoring='r2')\n",
    "print(score)\n",
    "max_score_index =np.argmax(score)\n",
    "train,test=folds[max_score_index]\n",
    "x_train,x_test,y_train,y_test = np.array(X)[train],np.array(X)[test],np.array(y)[train],np.array(y)[test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_ws.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "performance_ws = lr_ws.score(x_test, y_test)\n",
    "results['w2v_sent_c']=performance_ws\n",
    "print(performance_ws)\n",
    "test1=\"es el mejor profesor del mundo enseña muy bien hace las clases dinamicas\"\n",
    "test2=\"sus parciales son muy dificiles pero enseña bien\"\n",
    "test3=\"No se aprende nada en la materia pero al menos se pasa\"\n",
    "test4=\"La clase son solo tareas que pueden ser un poco largas, pero todo el tiempo de la clase se va en historias que poco o nada tienen que ver con los temas de la materia. Explica muy poca teoría.\"\n",
    "tests =[test1,test2,test3,test4]\n",
    "for i in range(len(tests)):\n",
    "    tests[i]=preprocessing_en(translate_sentence(tests[i]))\n",
    "sent=doc_to_sentiment_values(tests)\n",
    "test1=\"es el mejor profesor del mundo enseña muy bien hace las clases dinamicas\"\n",
    "test2=\"sus parciales son muy dificiles pero enseña bien\"\n",
    "test3=\"No se aprende nada en la materia pero al menos se pasa\"\n",
    "test4=\"La clase son solo tareas que pueden ser un poco largas, pero todo el tiempo de la clase se va en historias que poco o nada tienen que ver con los temas de la materia. Explica muy poca teoría.\"\n",
    "tests =[test1,test2,test3,test4]\n",
    "for i in range(len(tests)):\n",
    "    tests[i]=preprocessing(tests[i])\n",
    "w2v=w2v_repr1(tests)\n",
    "val = []\n",
    "for i in range(len(sent)):\n",
    "    val.append(sent[i]+list(w2v[i]))\n",
    "print(len(val))\n",
    "test_predictions=(lr_ws.predict(val))\n",
    "for i in range(len(tests)):\n",
    "    print(\"Entrada: \",tests[i],\"\\nPrediccion: \",round(test_predictions[i],2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Al parecer tomar word2vect + analisis sentimientos como datos de entrada para esta regresion lineal no dio ninguna mejoria, esto puede ser debido a que ambos metodos representan informacion similar del texto pero de una manera diferente, o que la forma de unir correcta de unir esta informacion no es simplemente concatenar los dos arreglos que representan el texto. En conclusion hasta no hallar un mejor metodo de unir estas dos representaciones lo mejor es usar una sola, para este caso especifico la mejor fue word2vect que dio mejores resultado."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict = lr_ws.predict(x_test)\n",
    "error={}\n",
    "l=len(y_test)\n",
    "for i in range(l):\n",
    "    diff = my_round(abs(y_test[i]-predict[i]))\n",
    "    if diff in error:\n",
    "        error[diff]+=1\n",
    "    else:\n",
    "        error[diff]=1\n",
    "for k in error.keys():\n",
    "    error[k]=round(error[k]/l,2)\n",
    "print(sorted(error.items()))\n",
    "differences['word2vect_sent_c']=sorted(error.items())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizacion de Resultados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!!pip3 install palettable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from matplotlib.pyplot import figure\n",
    "text_color='k'\n",
    "figure(num=None, figsize=(8, 6), dpi=80, facecolor=(1, 1, 1, 0), edgecolor='w')\n",
    "plt.rcParams['axes.facecolor'] = (0.2, 0.4, 0.6, 0)\n",
    "bar_c=plt.bar(range(len(results)), list(results.values()), align='center' ,color=(0.1, 0.1, 0.1, 0.1),  edgecolor=text_color)\n",
    "plt.xticks(range(len(results)), list(results.keys()),color=text_color, size=12,wrap=True)\n",
    "for rect in bar_c:\n",
    "    height = rect.get_height()\n",
    "    plt.text(rect.get_x() + rect.get_width()/2.0, height, '%.2f' %(height), ha='center', va='bottom',c=text_color,size=12)\n",
    "\n",
    "#'center', 'right', 'left'\n",
    "#'top', 'bottom', 'center', 'baseline', 'center_baseline'\n",
    "plt.title('R2 Calculado', color=text_color, size=20)\n",
    "plt.xlabel('categories',color=text_color)\n",
    "plt.ylabel('values',color=text_color)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.colors as mcolors\n",
    "print('Diferencia entre valor calculado y obtenido: ')\n",
    "from palettable.scientific.diverging import Roma_9\n",
    "for k,v in (differences.items()):\n",
    "    print(v)\n",
    "    colors = Roma_9.mpl_colors\n",
    "    values = [k1[1] for k1 in v]\n",
    "    explode =[0]*len(values)\n",
    "    max_index= values.index(max(values))\n",
    "    explode[max_index]=values[max_index]\n",
    "    labels = [k1[0] for k1 in v]\n",
    "    plt.pie(values, colors=colors, labels= [str(int(val*100))+'%' for val in values],explode=explode,counterclock=False, shadow=True)\n",
    "    plt.title(k,size=20)\n",
    "    plt.legend(labels,loc=3)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Proyecto3.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
